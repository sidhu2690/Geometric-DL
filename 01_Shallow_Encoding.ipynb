{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbhODvsWQM7+TUb4wRjTQa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidhu2690/Geometric-DL/blob/main/01_Shallow_Encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuXc_SgWj0Dt",
        "outputId": "3fec6cdb-a834-4013-aeea-19d03531dc91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive pairs:[(0, 1), (1, 2), (2, 3)]| Negative pairs: [(4, 0), (3, 4)]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def generate_training_pairs(edges, num_nodes, num_negatives=2):\n",
        "    pos_pairs = edges\n",
        "    edge_set = set(edges)\n",
        "\n",
        "    all_pairs = [(u, v) for u in range(num_nodes) for v in range(num_nodes) if u != v]\n",
        "    possible_negatives = [pair for pair in all_pairs if pair not in edge_set]\n",
        "    neg_pairs = random.choices(possible_negatives, k= num_negatives)\n",
        "\n",
        "    return pos_pairs, neg_pairs\n",
        "\n",
        "\n",
        "edges = [(0, 1), (1, 2), (2, 3)]\n",
        "pos, neg = generate_training_pairs(edges, num_nodes=5, num_negatives=2)\n",
        "\n",
        "print(f\"Positive pairs:{pos}| Negative pairs: {neg}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Only a few negatives are sampled (k=num_negatives) to reduce computation and enable efficient stochastic training instead of using all possible negative pairs.**\n"
      ],
      "metadata": {
        "id": "Gv83zMqB1ASe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Shallow embedding model\n",
        "class NodeEmbeddingModel:\n",
        "    def __init__(self, num_nodes, embedding_dim=4, lr=0.1):\n",
        "        self.num_nodes = num_nodes\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.lr = lr\n",
        "        self.embeddings = np.random.randn(num_nodes, embedding_dim)             # Initialize embeddings randomly\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def forward(self, u, v):\n",
        "        return np.dot(self.embeddings[u], self.embeddings[v])\n",
        "\n",
        "    def loss_and_grad(self, pairs, label):\n",
        "        losses = []\n",
        "        grads = np.zeros_like(self.embeddings)\n",
        "\n",
        "        for u, v in pairs:\n",
        "            score = self.forward(u, v)\n",
        "            pred = self.sigmoid(score)\n",
        "\n",
        "            # BCE loss: -[y log p + (1-y) log (1-p)]\n",
        "            loss = -(label * np.log(pred + 1e-10) + (1 - label) * np.log(1 - pred + 1e-10))\n",
        "            losses.append(loss)\n",
        "\n",
        "            error = (pred - label)\n",
        "            grads[u] += error * self.embeddings[v]\n",
        "            grads[v] += error * self.embeddings[u]\n",
        "\n",
        "        return np.mean(losses), grads / len(pairs)\n",
        "\n",
        "    def train_step(self, pos_pairs, neg_pairs):\n",
        "        pos_loss, pos_grads = self.loss_and_grad(pos_pairs, 1)\n",
        "        neg_loss, neg_grads = self.loss_and_grad(neg_pairs, 0)\n",
        "\n",
        "        total_loss = pos_loss + neg_loss\n",
        "        grads = pos_grads + neg_grads\n",
        "\n",
        "        # SGD\n",
        "        self.embeddings -= self.lr * grads\n",
        "        return total_loss\n"
      ],
      "metadata": {
        "id": "-_AQ104Lky4D"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges = [(0, 1), (1, 2), (2, 3)]\n",
        "num_nodes = 5\n",
        "embedding_dim = 3\n",
        "model = NodeEmbeddingModel(num_nodes, embedding_dim, lr=0.2)\n",
        "\n",
        "for epoch in range(500):\n",
        "    pos_pairs, neg_pairs = generate_training_pairs(edges, num_nodes, num_negatives=4)\n",
        "    loss = model.train_step(pos_pairs, neg_pairs)\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss = {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPTjKTnnlJO3",
        "outputId": "e48d87b2-6b38-4a9a-8074-7c847769e4cc"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss = 1.2746\n",
            "Epoch 100, Loss = 0.9397\n",
            "Epoch 200, Loss = 0.8365\n",
            "Epoch 300, Loss = 0.2181\n",
            "Epoch 400, Loss = 0.1983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Final embeddings: {model.embeddings}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICyyNPY9mek9",
        "outputId": "944a96a7-1867-4901-9db6-9fa0fd83c057"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final embeddings: [[-1.73491092 -0.97579543  2.42168662]\n",
            " [-1.15953029 -1.51811553 -0.87107437]\n",
            " [ 1.05168399 -1.06459263 -1.30776315]\n",
            " [ 3.0695279  -0.11112977  0.56342709]\n",
            " [-0.99380832  3.57506184 -0.89103276]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IoNUkshl2GtH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}